### Цель проекта:

Научить модель классификации комментариев на положительные и отрицательные. Опираемся на данные с разметкой о токсичности правок.


### Шаги выполнения проекта:

1. Предобработка данных.
2. Обучение моделей и проверка на тестовой выборке.

### В проекте использованы:

- WordNetLemmatizer
- TfidfVectorizer
- BertTokenizer
- BertConfig
- BertModel
- RandomForestClassifier
- LogisticRegressionCV
- GridSearchCV


### Краткое описание проекта:

Работа включала два этапа: предобработка данных и обучение моделей.

Предобработка проведена двумя вариантами: 
- при помощи мешка слов и оценки частоты употребления слов;
- при помощи модели BERT.

После предобработки данных были обучены 2 выбранные модели: логистическая регрессия и случайный лес. Поскольку метрикой качества в данном проекте являлась мера F1, равная по меньшей мере 0.75, этот показатель был взят за минимальное значение.


### Выводы по работе:

Целью данной работы являлось обучение моделей классификации комментариев на позитивные и негативные. 
Работа состояла из двух этапов: предобработки данных и обучения моделей.
Предобработка данных проводилась двумя способами: 
- при помощи создания мешка слов и оценки частоты употребления слов (TF-IDF и предшествующие величине токенизация и лемматизация);
- посредством векторного представления моделью BERT (с помощью преобразования текстов в эмбеддинги).

По итогам обучения и предсказания моделей можно сказать, что показатель свыше 0.75 был достигнут только логистической регрессией и только при подготовке данных при помощи величины TF-IDF. Разница между результатами предсказания на валидационной и тестовой выборке минимальна, поэтому переобучения не произошло.  
Соответственно, логистическая регрессия - та модель, которую стоит выбрать в данном случае.  
Тем не менее, не стоит упускать тот факт, что модель BERT работала лишь с частью данных. Результат получлся весьма неожиданным, и есть предположение, что при наличии больших мощностей, модель BERT предобработала бы данные лучше, и модель также показала бы лучший результат.
Проект завершен.
